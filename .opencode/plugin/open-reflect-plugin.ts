/**
 * Open-Reflect OpenCode Plugin
 * 
 * Plugin for OpenCode that provides self-learning and reflection capabilities.
 * 
 * Features:
 * - Captures corrections and positive feedback automatically
 * - Provides /repo command to process learnings
 * - Integrates with REFLECT.md knowledge base
 * - Supports knowledge evolution tracking
 */

import type { Plugin } from "@opencode-ai/plugin"
import { tool } from "@opencode-ai/plugin"
import { existsSync, mkdirSync, readFileSync, writeFileSync } from "fs"
import { join } from "path"

// ============================================================================
// Types
// ============================================================================

interface QueueEntry {
  id: string
  type: "correction" | "positive" | "explicit"
  confidence: number
  message: string
  timestamp: string
  project: string
  status: "pending" | "processed"
  processedAt?: string
}

interface PluginInput {
  client: {
    app: {
      log: (data: { service: string; level: string; message: string; extra?: Record<string, unknown> }) => Promise<void>
    }
    session: {
      prompt: (data: { path: { id: string }; body: { parts: Array<{ type: string; text: string }> } }) => Promise<void>
    }
  }
  project: { name: string; path: string }
  directory: string
  worktree: string
  $: {
    (strings: TemplateStringsArray, ...expressions: unknown[]): {
      quiet: () => Promise<{ exitCode: number; stdout: Uint8Array; stderr: Uint8Array }>
      text: () => Promise<string>
    }
    env: (env: Record<string, string | undefined>) => unknown
    cwd: (dir: string) => unknown
  }
}

// ============================================================================
// Pattern Definitions
// ============================================================================

const PATTERNS = {
  corrections: [
    { pattern: /no[,. ]+use/i, confidence: 0.90 },
    { pattern: /don't use/i, confidence: 0.90 },
    { pattern: /do not use/i, confidence: 0.90 },
    { pattern: /stop using/i, confidence: 0.90 },
    { pattern: /never use/i, confidence: 0.90 },
    { pattern: /that's (wrong|incorrect)/i, confidence: 0.85 },
    { pattern: /not right/i, confidence: 0.70 },
    { pattern: /^[.!?]*actually[,. ]/i, confidence: 0.65 },
    { pattern: /I meant/i, confidence: 0.80 },
    { pattern: /I (said|wrote|mentioned)\s+wrong/i, confidence: 0.60 },
    { pattern: /use .+ not/i, confidence: 0.85 }
  ],
  explicit: [
    { pattern: /^remember:/i, confidence: 0.95 },
    { pattern: /^note:/i, confidence: 0.95 },
    { pattern: /^important:/i, confidence: 0.95 }
  ],
  positive: [
    { pattern: /perfect!/i, confidence: 0.75 },
    { pattern: /exactly right/i, confidence: 0.75 },
    { pattern: /that's exactly/i, confidence: 0.75 },
    { pattern: /that's what I wanted/i, confidence: 0.75 },
    { pattern: /great approach/i, confidence: 0.70 },
    { pattern: /keep doing this/i, confidence: 0.80 },
    { pattern: /love it/i, confidence: 0.70 },
    { pattern: /excellent/i, confidence: 0.70 },
    { pattern: /nailed it/i, confidence: 0.70 }
  ]
}

// ============================================================================
// Utility Functions
// ============================================================================

function getErrorMessage(error: unknown): string {
  if (error instanceof Error) {
    return error.message
  }
  if (typeof error === "string") {
    return error
  }
  return "Unknown error"
}

function validateQueueData(data: unknown): data is QueueEntry[] {
  if (!Array.isArray(data)) return false
  return data.every(item =>
    typeof item === "object" &&
    item !== null &&
    typeof (item as any).id === "string" &&
    typeof (item as any).type === "string" &&
    typeof (item as any).confidence === "number" &&
    typeof (item as any).message === "string" &&
    typeof (item as any).timestamp === "string" &&
    typeof (item as any).project === "string" &&
    typeof (item as any).status === "string" &&
    ((item as any).processedAt === undefined || typeof (item as any).processedAt === "string")
  )
}

function getQueueFilePath(directory: string): string {
  const configDir = join(directory, ".opencode")
  const queueFile = join(configDir, "openreflect-queue.json")

  if (!existsSync(configDir)) {
    mkdirSync(configDir, { recursive: true })
  }

  if (!existsSync(queueFile)) {
    writeFileSync(queueFile, "[]", "utf-8")
  }

  return queueFile
}

function getReflectFilePath(directory: string): string {
  const reflectFile = join(directory, "REFLECT.md")
  
  if (!existsSync(reflectFile)) {
    const template = `# Open-Reflect Knowledge Evolution Log

> Open-Reflect intermediate learning records

## üéØ Learning Categories
*No learnings yet*

## üìú Evolution History
| Version | Date | Change Type | Description |

---
*Generated by Open-Reflect OpenCode Plugin*
`
    writeFileSync(reflectFile, template, "utf-8")
  }
  
  return reflectFile
}

function detectLearning(message: string): { type: string; confidence: number; matched: string } | null {
  // Check explicit markers first (highest priority)
  for (const { pattern, confidence } of PATTERNS.explicit) {
    if (pattern.test(message)) {
      return { type: "explicit", confidence, matched: pattern.source }
    }
  }
  
  // Check positive feedback
  for (const { pattern, confidence } of PATTERNS.positive) {
    if (pattern.test(message)) {
      return { type: "positive", confidence, matched: pattern.source }
    }
  }
  
  // Check corrections
  for (const { pattern, confidence } of PATTERNS.corrections) {
    if (pattern.test(message)) {
      return { type: "correction", confidence, matched: pattern.source }
    }
  }
  
  return null
}

async function addToQueue(input: PluginInput, message: string): Promise<void> {
  const queueFile = getQueueFilePath(input.directory)
  const detection = detectLearning(message)

  if (!detection) return

  try {
    const rawData = readFileSync(queueFile, "utf-8")
    const parsedData = JSON.parse(rawData)

    if (!validateQueueData(parsedData)) {
      throw new Error("Invalid queue data structure")
    }

    const learning: QueueEntry = {
      id: Date.now().toString(),
      type: detection.type as "correction" | "positive" | "explicit",
      confidence: detection.confidence,
      message: message.substring(0, 500),
      timestamp: new Date().toISOString(),
      project: input.project.name,
      status: "pending"
    }

    parsedData.push(learning)
    writeFileSync(queueFile, JSON.stringify(parsedData, null, 2), "utf-8")

    await input.client.app.log({
      service: "open-reflect",
      level: "info",
      message: `Learning captured: ${detection.type}`,
      extra: { confidence: detection.confidence }
    })
  } catch (error) {
    await input.client.app.log({
      service: "open-reflect",
      level: "error",
      message: `Failed to add learning to queue: ${getErrorMessage(error)}`,
      extra: { errorType: typeof error }
    })
  }
}

async function processLearnings(input: PluginInput): Promise<string> {
  const queueFile = getQueueFilePath(input.directory)

  try {
    const rawData = readFileSync(queueFile, "utf-8")
    const queueData = JSON.parse(rawData)

    if (!validateQueueData(queueData)) {
      return "‚ùå Queue data is corrupted. Please check openreflect-queue.json"
    }

    if (queueData.length === 0) {
      return "No pending learnings to process."
    }

    const reflectFile = getReflectFilePath(input.directory)
    let reflectContent = readFileSync(reflectFile, "utf-8")
    const timestamp = new Date().toISOString().split("T")[0]

    // Process each learning
    for (const learning of queueData) {
      if (learning.status === "pending") {
        const newEntry = `\n### ${timestamp}\n- ${learning.message} *(source: ${learning.type}, confidence: ${learning.confidence})*`

        const sectionMatch = reflectContent.match(/(## üéØ Learning Categories)/)
        if (sectionMatch) {
          const insertPoint = sectionMatch.index! + sectionMatch[0].length
          reflectContent = reflectContent.slice(0, insertPoint) + newEntry + reflectContent.slice(insertPoint)
        }

        learning.status = "processed"
        learning.processedAt = timestamp
      }
    }

    writeFileSync(reflectFile, reflectContent, "utf-8")
    writeFileSync(queueFile, JSON.stringify(queueData, null, 2), "utf-8")

    const processedCount = queueData.filter((l: QueueEntry) => l.status === "processed").length

    await input.client.app.log({
      service: "open-reflect",
      level: "info",
      message: `Processed ${processedCount} learnings`,
      extra: {}
    })

    return `‚úÖ Processed ${processedCount} learnings and updated REFLECT.md`
  } catch (error) {
    return `‚ùå Error processing learnings: ${getErrorMessage(error)}`
  }
}

async function clearQueue(input: PluginInput): Promise<string> {
  const queueFile = getQueueFilePath(input.directory)

  try {
    const rawData = readFileSync(queueFile, "utf-8")
    const queueData = JSON.parse(rawData)

    if (!validateQueueData(queueData)) {
      return "‚ùå Queue data is corrupted. Please check openreflect-queue.json"
    }

    const count = queueData.length

    // Clear queue
    writeFileSync(queueFile, "[]", "utf-8")

    await input.client.app.log({
      service: "open-reflect",
      level: "info",
      message: `Cleared ${count} learnings`,
      extra: { count }
    })

    return `üóëÔ∏è Cleared ${count} learnings.`
  } catch (error) {
    return `‚ùå Error clearing queue: ${getErrorMessage(error)}`
  }
}

async function exportQueue(input: PluginInput, format: "csv" | "json" | "markdown"): Promise<string> {
  const queueFile = getQueueFilePath(input.directory)

  try {
    const rawData = readFileSync(queueFile, "utf-8")
    const queueData = JSON.parse(rawData)

    if (!validateQueueData(queueData)) {
      return "‚ùå Queue data is corrupted"
    }

    if (queueData.length === 0) {
      return "‚ùå No learnings to export"
    }

    const timestamp = new Date().toISOString().split("T")[0]
    const exportDir = join(input.directory, ".opencode", "exports")

    if (!existsSync(exportDir)) {
      mkdirSync(exportDir, { recursive: true })
    }

    let content = ""
    let fileName = ""

    if (format === "csv") {
      fileName = `learnings-${timestamp}.csv`
      const headers = "ID,Type,Confidence,Message,Timestamp,Status\n"
      const rows = queueData.map((l: QueueEntry) =>
        `"${l.id}","${l.type}",${l.confidence},"${l.message.replace(/"/g, '""')}","${l.timestamp}","${l.status}"`
      ).join("\n")
      content = headers + rows
    } else if (format === "markdown") {
      fileName = `learnings-${timestamp}.md`
      content = `# Learning Export - ${timestamp}\n\n`
      for (const learning of queueData) {
        const icon = learning.type === "explicit" ? "üî¥" :
          learning.type === "correction" ? "üîÑ" :
            learning.type === "positive" ? "‚úÖ" : "üìù"
        content += `${icon} **${learning.type}** (${learning.confidence}%)\n`
        content += `> ${learning.message}\n`
        content += `> _${learning.timestamp}_\n\n`
      }
    } else {
      fileName = `learnings-${timestamp}.json`
      content = JSON.stringify(queueData, null, 2)
    }

    const filePath = join(exportDir, fileName)
    writeFileSync(filePath, content, "utf-8")

    await input.client.app.log({
      service: "open-reflect",
      level: "info",
      message: `Exported ${queueData.length} learnings to ${format}`,
      extra: { fileName, count: queueData.length }
    })

    return `‚úÖ Exported ${queueData.length} learnings to ${fileName}\nLocation: ${filePath}`
  } catch (error) {
    return `‚ùå Error exporting queue: ${getErrorMessage(error)}`
  }
}

async function viewQueue(input: PluginInput): Promise<string> {
  const queueFile = getQueueFilePath(input.directory)

  try {
    const rawData = readFileSync(queueFile, "utf-8")
    const queueData = JSON.parse(rawData)

    if (!validateQueueData(queueData)) {
      return "‚ùå Queue data is corrupted. Please check openreflect-queue.json"
    }

    if (queueData.length === 0) {
      return "üì≠ No pending learnings. System is up to date."
    }

    let output = `üìä **Pending Learnings: ${queueData.length}**\n\n`

    for (let i = 0; i < queueData.length; i++) {
      const learning = queueData[i]
      const icon = learning.type === "explicit" ? "üî¥" :
        learning.type === "correction" ? "üîÑ" :
          learning.type === "positive" ? "‚úÖ" : "üìù"

      output += `${icon} **#${i + 1}** ${learning.type} (${learning.confidence}%)\n`
      output += `   ${learning.message.substring(0, 80)}${learning.message.length > 80 ? "..." : ""}\n`
      output += `   _${learning.timestamp}_\n\n`
    }

    output += `---\nüí° Run \`/repo\` to process these learnings`

    return output
  } catch (error) {
    return `‚ùå Error viewing queue: ${getErrorMessage(error)}`
  }
}

// ============================================================================
// Main Plugin
// ============================================================================

export const OpenReflectPlugin: Plugin = async ({ client, project, directory, worktree, $ }) => {
  await client.app.log({
    service: "open-reflect",
    level: "info",
    message: "Open-Reflect plugin initialized",
    extra: { project: project.name }
  })
  
  return {
    // Session compaction hook - remind user about pending learnings
    "session.compacted": async (input, output) => {
      const queueFile = getQueueFilePath(directory)

      try {
        const rawData = readFileSync(queueFile, "utf-8")
        const queueData = JSON.parse(rawData)

        if (!validateQueueData(queueData)) {
          await client.app.log({
            service: "open-reflect",
            level: "warn",
            message: "Queue data is corrupted",
            extra: {}
          })
          return
        }

        const pendingCount = queueData.filter((l: QueueEntry) => l.status === "pending").length

        if (pendingCount > 0) {
          output.context.push(`## Open-Reflect Learnings\nYou have ${pendingCount} pending learnings. Run /repo to process them.`)

          await client.app.log({
            service: "open-reflect",
            level: "warn",
            message: `${pendingCount} pending learnings before compaction`,
            extra: {}
          })
        }
      } catch (error) {
        await client.app.log({
          service: "open-reflect",
          level: "error",
          message: `Failed to check queue during compaction: ${getErrorMessage(error)}`,
          extra: {}
        })
      }
    },
    
    // Tool execution before - detect corrections in tool arguments
    "tool.execute.before": async (input, output) => {
      const argsStr = JSON.stringify(input.args)
      const detection = detectLearning(argsStr)
      
      if (detection) {
        await addToQueue({ client, project, directory, worktree, $ }, argsStr)
      }
    },

    // Message updated - detect corrections in messages
    "message.updated": async (input) => {
      const detection = detectLearning(input.content)

      if (detection) {
        await addToQueue({ client, project, directory, worktree, $ }, input.content)
      }
    },
    
    // Custom tools
    tool: {
      repo: tool({
        description: "Process pending learnings and update REFLECT.md. Use --view to see queue without processing.",
        args: {
          command: tool.schema.string().describe("Optional command: --view to view queue only")
        },
        async execute(args, ctx) {
          if (args.command === "--view") {
            return await viewQueue(ctx as PluginInput)
          }
          return await processLearnings(ctx as PluginInput)
        }
      }),

      "skip-reflect": tool({
        description: "Clear all pending learnings without processing",
        args: {},
        async execute(_, ctx) {
          return await clearQueue(ctx as PluginInput)
        }
      }),

      "view-queue": tool({
        description: "View pending learnings without processing",
        args: {},
        async execute(_, ctx) {
          return await viewQueue(ctx as PluginInput)
        }
      }),

      "export-reflect": tool({
        description: "Export learnings to CSV, JSON, or Markdown format",
        args: {
          format: tool.schema.enum("csv", "json", "markdown").describe("Export format: csv, json, or markdown")
        },
        async execute(args, ctx) {
          return await exportQueue(ctx as PluginInput, args.format as "csv" | "json" | "markdown")
        }
      })
    }
  }
}
